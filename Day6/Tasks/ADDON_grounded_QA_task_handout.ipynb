{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f3f25ed",
   "metadata": {},
   "source": [
    "# Task 1: Implement a simple Q&A in Langchain\n",
    "\n",
    "- register to OpenAI API (use the \"start for free\" credits defined [here](https://openai.com/pricing)\n",
    "- use [langchain](https://python.langchain.com/en/latest/)\n",
    "- use the standard OpenAI model to ask the question and oserve the answer:\n",
    "\n",
    "`When was the vilnius TV tower donated by France?`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34fb7ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# install the packages\n",
    "....."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a74b709",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get OpenAI key from user input\n",
    "from getpass import getpass\n",
    "\n",
    "OPENAI_API_KEY = getpass()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "659a49f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#put the OpenAI key to the OS context\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "import os\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "262697c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize a LangChain language model connector object\n",
    "\n",
    "....."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d1244f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate, LLMChain\n",
    "\n",
    "#create the text of the prompt template\n",
    "#pay attention to the \"keys\", or \"variables\" that LangChain will interpolate into the prompt text!\n",
    "template = .....\n",
    "\n",
    "#create a PromptTemplate object  from the template text\n",
    "prompt = .....\n",
    "\n",
    "#create an llm chain with the LLM and the prompt objects\n",
    "llm_chain = .....\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b8555d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ask the question from the chain\n",
    "question = \"When was the vilnius TV tower donated by France? \"\n",
    "\n",
    "#print the result\n",
    "print(llm_chain.run(question))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5f1a390",
   "metadata": {},
   "source": [
    "# Task 2:\n",
    "\n",
    "- Install the [wikipedia package](https://pypi.org/project/wikipedia/)\n",
    "- get the page contents describing the Vilnius TV tower\n",
    "- implement a \"gounded\" question answering solution, where the OpenAI chat gets additional context with the question, and an appropriate prompt that forces it to refuse to hallucinate information beyond the given context\n",
    "- use the Wikipedia page content as context\n",
    "- pose the same question and observe the answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea176b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#install and import Wikipedia\n",
    "!pip install wikipedia > /dev/null\n",
    "import wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba2a519",
   "metadata": {},
   "outputs": [],
   "source": [
    "#download the page content from Wikipadia as context\n",
    "....."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcdbcfb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8126c9d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate, LLMChain\n",
    "\n",
    "#create the text of the prompt template\n",
    "#pay attention to the \"keys\", or \"variables\" that LangChain will interpolate into the prompt text!\n",
    "template = .....\n",
    "\n",
    "#create a PromptTemplate object  from the template text\n",
    "prompt = .....\n",
    "\n",
    "#create an llm chain with the LLM and the prompt objects\n",
    "llm_chain = ....."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ca94af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ask the question from the chain\n",
    "question = \"When was the vilnius TV tower donated by France? \"\n",
    "\n",
    "#print the result\n",
    "print(llm_chain.run({\"context\":context,\"question\":question}))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
