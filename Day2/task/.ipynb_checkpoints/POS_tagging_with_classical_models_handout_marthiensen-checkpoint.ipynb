{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "no_k76e0NZHI"
   },
   "source": [
    "# Task: Part of speech tagging\n",
    "\n",
    "In this task we try to recreate a very rudimentary POS tagger \"from scratch\" using SpaCy and CRF models. \n",
    "\n",
    "(We disregard the fact, that SpaCy has a built in POS tagger for the moment for demonstration purposes.)\n",
    "\n",
    "The input is a tokenized English sentence. The task is to label each word with a part of speech (POS) tag. The tag set, which is identical the [Universal Dependencies project's](https://universaldependencies.org/) basic tag set is the following:\n",
    "\n",
    "- NOUN: noun\n",
    "- VERB: verb\n",
    "- DET: determiner\n",
    "- ADJ: adjective\n",
    "- ADP: adposition (e.g., prepositions)\n",
    "- ADV: adverb\n",
    "- CONJ: conjunction\n",
    "- NUM: numeral\n",
    "- PART: particle (function word that cannot be inflected, has no meaning in\n",
    "  itself and doesn't fit elsewhere, e.g., \"to\")\n",
    "- PRON: pronoun\n",
    "- .: punctuation\n",
    "- X: other\n",
    "\n",
    "The code in this task is an adaptation of the NER code in the sklearn-crfsuite documentation.\n",
    "\n",
    "# The data set\n",
    "\n",
    "__Brown__ corpus: \"The Brown University Standard Corpus of Present-Day American English (or just Brown Corpus) was compiled in the 1960s by Henry Kuƒçera and W. Nelson Francis at Brown University, Providence, Rhode Island as a general corpus (text collection) in the field of corpus linguistics. It contains 500 samples of English-language text, totaling roughly one million words, compiled from works published in the United States in 1961\" (Wikpedia: Brown Corpus)\n",
    "\n",
    "Let's download and inspect the data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-12T09:32:20.712982Z",
     "start_time": "2019-11-12T09:32:16.093693Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "id": "KAPwh8mmNZHM",
    "outputId": "09c0b6f3-d1cd-45d4-8d81-e3b3d32cef20"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to\n",
      "[nltk_data]     /Users/nilsmart96/nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['The', 'Fulton', 'County', 'Grand', 'Jury', 'said', ...]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "from nltk.corpus import brown\n",
    "nltk.download('brown')\n",
    "\n",
    "brown.words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-12T09:32:21.291370Z",
     "start_time": "2019-11-12T09:32:20.723897Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "id": "3kSgq4e0NZHi",
    "outputId": "bc8efdec-092d-4cde-c35d-cc16de45da7b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package universal_tagset to\n",
      "[nltk_data]     /Users/nilsmart96/nltk_data...\n",
      "[nltk_data]   Package universal_tagset is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('The', 'DET'), ('Fulton', 'NOUN'), ...]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('universal_tagset')\n",
    "brown.tagged_words(tagset='universal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-12T09:32:21.352042Z",
     "start_time": "2019-11-12T09:32:21.297210Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "colab_type": "code",
    "id": "9tT1DBTtNZHu",
    "outputId": "9c1ed6f2-d1b0-4b54-8497-3864785a115a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['The', 'Fulton', 'County', 'Grand', 'Jury', 'said', 'Friday', 'an', 'investigation', 'of', \"Atlanta's\", 'recent', 'primary', 'election', 'produced', '``', 'no', 'evidence', \"''\", 'that', 'any', 'irregularities', 'took', 'place', '.'], ['The', 'jury', 'further', 'said', 'in', 'term-end', 'presentments', 'that', 'the', 'City', 'Executive', 'Committee', ',', 'which', 'had', 'over-all', 'charge', 'of', 'the', 'election', ',', '``', 'deserves', 'the', 'praise', 'and', 'thanks', 'of', 'the', 'City', 'of', 'Atlanta', \"''\", 'for', 'the', 'manner', 'in', 'which', 'the', 'election', 'was', 'conducted', '.'], ...]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brown.sents()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-12T09:32:25.131849Z",
     "start_time": "2019-11-12T09:32:21.365202Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "UuwBB-XRNZH6",
    "outputId": "10da7445-8b1f-43a1-eed0-2a36ef304951"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1161192"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(brown.words())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "m8VYZmFCsNTa"
   },
   "source": [
    "From the brown the object provided by NLTK we will work with the tagged sentence list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-12T09:32:25.163453Z",
     "start_time": "2019-11-12T09:32:25.136038Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "bh0wAJkWNnlV",
    "outputId": "d314dffa-af1b-4a35-9859-2e51f48245ec"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('The', 'DET'),\n",
       "  ('Fulton', 'NOUN'),\n",
       "  ('County', 'NOUN'),\n",
       "  ('Grand', 'ADJ'),\n",
       "  ('Jury', 'NOUN'),\n",
       "  ('said', 'VERB'),\n",
       "  ('Friday', 'NOUN'),\n",
       "  ('an', 'DET'),\n",
       "  ('investigation', 'NOUN'),\n",
       "  ('of', 'ADP'),\n",
       "  (\"Atlanta's\", 'NOUN'),\n",
       "  ('recent', 'ADJ'),\n",
       "  ('primary', 'NOUN'),\n",
       "  ('election', 'NOUN'),\n",
       "  ('produced', 'VERB'),\n",
       "  ('``', '.'),\n",
       "  ('no', 'DET'),\n",
       "  ('evidence', 'NOUN'),\n",
       "  (\"''\", '.'),\n",
       "  ('that', 'ADP'),\n",
       "  ('any', 'DET'),\n",
       "  ('irregularities', 'NOUN'),\n",
       "  ('took', 'VERB'),\n",
       "  ('place', 'NOUN'),\n",
       "  ('.', '.')],\n",
       " [('The', 'DET'),\n",
       "  ('jury', 'NOUN'),\n",
       "  ('further', 'ADV'),\n",
       "  ('said', 'VERB'),\n",
       "  ('in', 'ADP'),\n",
       "  ('term-end', 'NOUN'),\n",
       "  ('presentments', 'NOUN'),\n",
       "  ('that', 'ADP'),\n",
       "  ('the', 'DET'),\n",
       "  ('City', 'NOUN'),\n",
       "  ('Executive', 'ADJ'),\n",
       "  ('Committee', 'NOUN'),\n",
       "  (',', '.'),\n",
       "  ('which', 'DET'),\n",
       "  ('had', 'VERB'),\n",
       "  ('over-all', 'ADJ'),\n",
       "  ('charge', 'NOUN'),\n",
       "  ('of', 'ADP'),\n",
       "  ('the', 'DET'),\n",
       "  ('election', 'NOUN'),\n",
       "  (',', '.'),\n",
       "  ('``', '.'),\n",
       "  ('deserves', 'VERB'),\n",
       "  ('the', 'DET'),\n",
       "  ('praise', 'NOUN'),\n",
       "  ('and', 'CONJ'),\n",
       "  ('thanks', 'NOUN'),\n",
       "  ('of', 'ADP'),\n",
       "  ('the', 'DET'),\n",
       "  ('City', 'NOUN'),\n",
       "  ('of', 'ADP'),\n",
       "  ('Atlanta', 'NOUN'),\n",
       "  (\"''\", '.'),\n",
       "  ('for', 'ADP'),\n",
       "  ('the', 'DET'),\n",
       "  ('manner', 'NOUN'),\n",
       "  ('in', 'ADP'),\n",
       "  ('which', 'DET'),\n",
       "  ('the', 'DET'),\n",
       "  ('election', 'NOUN'),\n",
       "  ('was', 'VERB'),\n",
       "  ('conducted', 'VERB'),\n",
       "  ('.', '.')]]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sents = brown.tagged_sents(tagset=\"universal\")\n",
    "\n",
    "sents[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-12T09:32:28.899336Z",
     "start_time": "2019-11-12T09:32:25.166107Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "L2oUMrTpasZY",
    "outputId": "d644b14c-77a1-4044-deb1-02a127bd31ca"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57340"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tgvacV45sNTz"
   },
   "source": [
    "We divide our data set into a train and a valid part:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-12T09:32:28.905030Z",
     "start_time": "2019-11-12T09:32:28.901963Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "jPvFic-atE6S"
   },
   "outputs": [],
   "source": [
    "valid_sents = sents[:5734]\n",
    "train_sents = sents[5734:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zO8hXBHHPR4f"
   },
   "source": [
    "# Feature template\n",
    "\n",
    "Since the plan is to build a CRF model, we need a __feature template__, which generates features for a word in a sentence (our sequence in the sequence tagging task). We use spaCy for feature extraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-12T09:32:36.258620Z",
     "start_time": "2019-11-12T09:32:28.906793Z"
    }
   },
   "outputs": [],
   "source": [
    "#Spacy install, load and such stuff\n",
    "# Running locally\n",
    "# !pip install spacy\n",
    "# python -m spacy download en_core_web_sm\n",
    "\n",
    "#Import\n",
    "import spacy\n",
    "from spacy.tokens import Doc\n",
    "\n",
    "#By model load, please deactivate unnecessary pipeline elements!\n",
    "en = spacy.blank(\"en\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TC4f13w9sNUJ"
   },
   "source": [
    "We write a function which generates features for a token in a sentence, which is already a spaCy document. The feature vector is represented as a `dict` mapping feature names to their values.\n",
    "\n",
    "The desired **feature set for a token is**:\n",
    "\n",
    "- `bias`: A constant value of 1 as an input\n",
    "- `token.lower`: the lowercased textual form of the token\n",
    "- `token.suffix`: the textual form of the token's suffix as defined by SpaCy,\n",
    "- `token.prefix`: the textual form of the token's prefix as defined by SpaCy,\n",
    "- `token.is_upper`: boolean value indicating if the token is uppercase,\n",
    "- `token.is_title`: boolean value indicating if the token is a title,\n",
    "- `token.is_digit`: boolean value indicating if the token consists of numbers.\n",
    "\n",
    "These are only the `Token`'s own properties, but they represent no context.\n",
    "\n",
    "We would like to include information about  the previous and next words, as well as indicating if the `Token` is the beginning or the end of sentence.\n",
    "\n",
    "The **contextual features** should be:\n",
    " \n",
    "- `-1:token.lower`: What is the lowercase textual form of the previous token?,\n",
    "- `-1:token.is_title`: Is the previous token a title?,\n",
    "- `-1:token.is_upper`: Is the previous token uppercase?,\n",
    "- `+1:token.lower`: What is the lowercase textual form of the next token?,\n",
    "- `+1:token.is_title`: Is the next token a title?,\n",
    "- `+1:token.is_upper`: Is the next token uppercase?,\n",
    "- `BOS`: Boolean value indicating if the token is the beginning of a sentence,\n",
    "- `EOS`: Boolean value indicating if the token is the end of a sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-12T09:32:37.930451Z",
     "start_time": "2019-11-12T09:32:37.909065Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "SKz9zT8bsNUL"
   },
   "outputs": [],
   "source": [
    "def token2features(sent, i):\n",
    "    \"\"\"Return a feature dict for a token. \n",
    "    sent is a spaCy Doc containing a sentence, i is the token's index in it.\n",
    "    \"\"\"\n",
    "    token = sent[i]\n",
    "    features = {\n",
    "        'bias': 1.0,\n",
    "        'token.lower': token.text.lower(),\n",
    "        'token.suffix': token.suffix_,\n",
    "        'token.prefix': token.prefix_,\n",
    "        'token.is_upper': token.is_upper,\n",
    "        'token.is_title': token.is_title,\n",
    "        'token.is_digit': token.is_digit,\n",
    "        '-1:token.lower': sent[i-1].text.lower() if i > 0 else '',\n",
    "        '-1:token.is_title': sent[i-1].is_title if i > 0 else False,\n",
    "        '-1:token.is_upper': sent[i-1].is_upper if i > 0 else False,\n",
    "        '+1:token.lower': sent[i+1].text.lower() if i < len(sent)-1 else '',\n",
    "        '+1:token.is_title': sent[i+1].is_title if i < len(sent)-1 else False,\n",
    "        '+1:token.is_upper': sent[i+1].is_upper if i < len(sent)-1 else False,\n",
    "        'BOS': i == 0,\n",
    "        'EOS': i == len(sent)-1,\n",
    "    }\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VvwL0hF3sNUS"
   },
   "source": [
    "For training, we will also need functions to generate feature dict and label lists for sentences in our training corpus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-12T09:32:37.958184Z",
     "start_time": "2019-11-12T09:32:37.936592Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "ZLW80wtksNUU"
   },
   "outputs": [],
   "source": [
    "def sent2features(sent):\n",
    "    \"Return a list of feature dicts for a sentence in the data set.\"\n",
    "    # Create a doc by instantiating a Doc class and iterating through the sentence token by token.\n",
    "    # Please bear in mind, that Brown has token-POS pairs, latter one we don't need here...\n",
    "    sent_text = [entry[0] for entry in sent]\n",
    "    doc = Doc(en.vocab, words=sent_text)\n",
    "    # Plese use the above defined token2features function on each token to generate the features\n",
    "    # For the whole sentence!\n",
    "    sent_features = [token2features(doc, i) for i in range(len(doc))]\n",
    "    \n",
    "    return sent_features\n",
    "\n",
    "def sent2labels(sent):\n",
    "    #Please create / filter only the labels for given sentence!\n",
    "    labels = [entry[1] for entry in sent]\n",
    "    \n",
    "    return labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pBoPuzeMsNUa"
   },
   "source": [
    "Sanity check: let's see the values for the first 2 tokens in the corpus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-12T09:32:37.997140Z",
     "start_time": "2019-11-12T09:32:37.966347Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 74
    },
    "colab_type": "code",
    "id": "UcqvDIJofccv",
    "outputId": "7e47bfb1-346c-4a04-82d7-ead92f35050d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'bias': 1.0, 'token.lower': 'the', 'token.suffix': 'The', 'token.prefix': 'T', 'token.is_upper': False, 'token.is_title': True, 'token.is_digit': False, '-1:token.lower': '', '-1:token.is_title': False, '-1:token.is_upper': False, '+1:token.lower': 'fulton', '+1:token.is_title': True, '+1:token.is_upper': False, 'BOS': True, 'EOS': False}, {'bias': 1.0, 'token.lower': 'fulton', 'token.suffix': 'ton', 'token.prefix': 'F', 'token.is_upper': False, 'token.is_title': True, 'token.is_digit': False, '-1:token.lower': 'the', '-1:token.is_title': True, '-1:token.is_upper': False, '+1:token.lower': 'county', '+1:token.is_title': True, '+1:token.is_upper': False, 'BOS': False, 'EOS': False}]\n",
      "['DET', 'NOUN']\n"
     ]
    }
   ],
   "source": [
    "print(sent2features(sents[0])[:2])\n",
    "print(sent2labels(sents[0])[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KsoK0-GNfzt5"
   },
   "source": [
    "# Putting the data into final form"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ylfst7VGsNUl"
   },
   "source": [
    "Everything is ready to generate the training data in the form which is usable for the CRFsuite. Note that our inputs and labels will be  2-level representations, lists of lists, because we deal with token sequences (sentences)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-12T09:33:02.066506Z",
     "start_time": "2019-11-12T09:32:38.005545Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "Wfqa0feYgspT",
    "outputId": "7503580f-e5a4-4c56-80b2-9c70bbd1cce2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.27 s, sys: 288 ms, total: 7.56 s\n",
      "Wall time: 7.56 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train = [sent2features(s) for s in train_sents]\n",
    "y_train = [sent2labels(s) for s in train_sents]\n",
    "\n",
    "X_valid = [sent2features(s) for s in valid_sents]\n",
    "y_valid = [sent2labels(s) for s in valid_sents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-12T09:33:02.072026Z",
     "start_time": "2019-11-12T09:33:02.068258Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 110
    },
    "colab_type": "code",
    "id": "XNFvu0UosNUt",
    "outputId": "9195a73b-b3bb-46af-cc61-1e7e23e2a0ed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature dict for the first token in the first validation sentence:\n",
      "{'bias': 1.0, 'token.lower': 'the', 'token.suffix': 'The', 'token.prefix': 'T', 'token.is_upper': False, 'token.is_title': True, 'token.is_digit': False, '-1:token.lower': '', '-1:token.is_title': False, '-1:token.is_upper': False, '+1:token.lower': 'fulton', '+1:token.is_title': True, '+1:token.is_upper': False, 'BOS': True, 'EOS': False}\n",
      "Its label:\n",
      "DET\n"
     ]
    }
   ],
   "source": [
    "print(\"Feature dict for the first token in the first validation sentence:\")\n",
    "print(X_valid[0][0])\n",
    "print(\"Its label:\")\n",
    "print(y_valid[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "f2siQxe9k4ql"
   },
   "source": [
    "# Training and evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xwyn356ysNU2"
   },
   "source": [
    "We use the super-optimized [CRFsuite](http://www.chokkan.org/software/crfsuite/) via the scikit-learn compatible [sklearn-crfsuite](https://sklearn-crfsuite.readthedocs.io) wrapper to train a CRF model on the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-12T09:33:04.830327Z",
     "start_time": "2019-11-12T09:33:02.073675Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "colab_type": "code",
    "id": "15POzt86sNSe",
    "outputId": "c1ba53b0-e73a-46c9-b09e-53e5f848ed48"
   },
   "outputs": [],
   "source": [
    "%%capture # only to avoid ugly printouts during install\n",
    "!pip install sklearn_crfsuite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-12T09:33:04.883741Z",
     "start_time": "2019-11-12T09:33:04.836395Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "WkX57BFDklEL"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token-wise classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           .       1.00      1.00      1.00     14377\n",
      "         ADJ       0.91      0.92      0.92      8525\n",
      "         ADP       0.98      0.98      0.98     15138\n",
      "         ADV       0.93      0.93      0.93      4438\n",
      "        CONJ       0.99      1.00      1.00      3435\n",
      "         DET       1.00      1.00      1.00     14128\n",
      "        NOUN       0.98      0.97      0.98     36341\n",
      "         NUM       0.99      0.98      0.98      2386\n",
      "        PRON       0.99      0.99      0.99      3427\n",
      "         PRT       0.94      0.93      0.94      2877\n",
      "        VERB       0.97      0.98      0.97     18229\n",
      "           X       0.87      0.59      0.70       100\n",
      "\n",
      "    accuracy                           0.98    123401\n",
      "   macro avg       0.96      0.94      0.95    123401\n",
      "weighted avg       0.98      0.98      0.98    123401\n",
      "\n",
      "Average Sentence-wise F1 Score: 0.97\n"
     ]
    }
   ],
   "source": [
    "# Please import and train an averaged perceptron model from CRFsuite and use it's custom metrics, \n",
    "# especially the multiple forms of accuracy score to evaluate the model!\n",
    "\n",
    "import sklearn_crfsuite\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "\n",
    "# Initialize the CRF model\n",
    "crf = sklearn_crfsuite.CRF(\n",
    "    algorithm='ap',  # Averaged Perceptron\n",
    "    max_iterations=100,\n",
    "    all_possible_transitions=True\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "crf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = crf.predict(X_valid)\n",
    "\n",
    "# Flatten the true and predicted labels for evaluation (Tokens)\n",
    "y_test_token = [label for sent_labels in y_valid for label in sent_labels]\n",
    "y_pred_token = [label for sent_preds in y_pred for label in sent_preds]\n",
    "\n",
    "# Evaluate the model using custom metrics\n",
    "# Token Classification Report\n",
    "print(\"Token-wise classification report:\")\n",
    "print(classification_report(y_test_token, y_pred_token))\n",
    "\n",
    "# Sentence-wise F1 Score for comparison\n",
    "sent_f1_sum = 0\n",
    "for true_labels_sentence, pred_labels_sentence in zip(y_valid, y_pred):\n",
    "    f1_sentence = f1_score(true_labels_sentence, pred_labels_sentence, average=\"micro\")\n",
    "    sent_f1_sum += f1_sentence\n",
    "avg_sent_f1 = round(sent_f1_sum / len(y_valid), 2)\n",
    "print(f\"Average Sentence-wise F1 Score: {avg_sent_f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please draw some conclusion if this model is \"good enough\" \n",
    "# in your view if you take token level and sentence level metrics into account!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the provided results for POS tagging, the model appears to perform quite well. Let's analyze the key metrics and draw some conclusions:\n",
    "\n",
    "1. **Accuracy:**\n",
    "   - The overall accuracy of the model is 98%, which is high. This suggests that the model correctly predicts the part-of-speech tags for the majority of tokens in the dataset.\n",
    "\n",
    "2. **Macro and Weighted Averages:**\n",
    "   - There is a noticable difference between the macro and the weighted average values, with the weighted average being a few percentage points stronger for Precision, Recall and F1 respectively. This indicates strong overall performance across all classes, with more emphasis on the larger classes.\n",
    "\n",
    "3. **Token Level and Sentence Level Metrics:**\n",
    "   - At the token level, the precision, recall, and F1-scores are provided for each POS tag, giving a detailed view of the model's performance on individual tokens.\n",
    "   - Some classes, such as \"X\", \"PRT\", \"ADJ\" or \"ADV\" have lower scores. All of these appear less often in the dataset, as can be seen in the support column. It could be the case that these metrics are improved with more training data. This is supported by the high weighted average values for Precision, Recall and F1 as previously mentioned.\n",
    "   - The average sentence-wise F1 score is also high (0.97), indicating that the model performs well at the sentence level. This metric is particularly important as it assesses how well the model captures the sequential dependencies and overall structure of sentences.\n",
    "\n",
    "4. **Consideration of \"Good Enough\":**\n",
    "   - The model seems to be performing well, especially considering the high precision, recall, and F1-scores across most POS tags.\n",
    "   - Whether the model is \"good enough\" depends on the specific requirements of your application. In many NLP tasks, achieving an accuracy of around 98% would be considered quite good.\n",
    "   - It's essential to consider the practical implications of the errors made by the model. For example, if misclassifying certain POS tags has a significant impact on downstream tasks, further improvements may be necessary.\n",
    "   - If possible, a larger dataset could help mitigate the worse performance of some of the less frequently used tags.\n",
    "\n",
    "In conclusion, the provided POS tagging model seems to be quite effective. Sentence and token level performance is on a similarly high level. Whether it is good enogh depends on the specific use case, but I deem it good enogh for this assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "63p9RtDhsNU_"
   },
   "source": [
    "Let's instantiate and fit our model. CRFsuite implements several learning methods, here we use \"ap\", i.e., averaged perceptron."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "li8CXg67sNVc"
   },
   "source": [
    "# Demonstration\n",
    "\n",
    "Just for the fun, we can try out the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-12T09:35:17.983727Z",
     "start_time": "2019-11-12T09:35:17.965723Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "JHoYAGHFsNVe"
   },
   "outputs": [],
   "source": [
    "def predict_tags(sent):\n",
    "    \"\"\"Predict tags for a sentence.\n",
    "    sent is a string.\n",
    "    \"\"\"\n",
    "    doc = en(sent)\n",
    "    return crf.predict([[token2features(doc, i) for i in range(len(doc))]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-12T09:35:37.676093Z",
     "start_time": "2019-11-12T09:35:17.986500Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 182
    },
    "colab_type": "code",
    "id": "Ya59xso_z7uj",
    "outputId": "401e3223-c177-420b-8d2e-0120707dac1c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['DET', 'NOUN', 'VERB', 'DET', 'NOUN', 'ADP', 'DET', 'NOUN', 'ADP', 'PRON', '.']]\n",
      "[['ADV', 'PRON', 'PRON', 'ADV', 'VERB', '.']]\n",
      "[['NOUN', 'NUM', 'NOUN', 'VERB', 'ADV', 'ADJ', 'CONJ', 'ADJ', '.']]\n",
      "\n",
      "Empty input received -- bye!\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    sent = input(\"\\nEnter a sentence to tag or press return to quit:\\n\")\n",
    "    if sent:\n",
    "        print(predict_tags(sent))\n",
    "    else:\n",
    "        print(\"\\nEmpty input received -- bye!\")\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "POS_tagging_with_classical_models.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
