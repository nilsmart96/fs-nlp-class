{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FSKsTvhZ2dpw"
   },
   "source": [
    "# Syntax\n",
    "\n",
    "Syntactic theories aim to characterize\n",
    "\n",
    "> the set of rules or principles that govern how words are put together to form phrases, well formed\n",
    "sequences of words.\n",
    "\n",
    "([Koopman et al.: An Introduction to Syntactic Analysis and Theory, p. 1](https://linguistics.ucla.edu/people/stabler/isat.pdf))\n",
    "\n",
    "The most important \"well formed sequences\" in this context are __sentences__: the central goal of syntactic theories for a given language is to find structural rules or principles that characterize/delineate __well formed/grammatical sentences__ of the language in question.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GZwv2KCM2dp0"
   },
   "source": [
    "Modern syntactic theories do this by defining structural rules for generating, and -- in the other direction -- parsing, i.e. structurally describing sentences. A sentence is considered to be syntactically well-formed or __grammatical__ if there is a parse or structural description of it which satisfy the syntactic constraints of the theory in question.\n",
    "\n",
    "Grammaticality doesn't necessarily mean coherence or meaningfulness: To use Chomsky's famous example, the sentence\n",
    "\n",
    "> Colorless green ideas sleep furiously.\n",
    "\n",
    "is totally well formed, but semantically nonsensical, in contrast to the similar\n",
    "\n",
    "> Furiously sleep ideas green colorless.\n",
    "\n",
    "which is ungrammatical as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y1Qz7xNt2dp0"
   },
   "source": [
    "For NLP purposes, we won't be interested so much in deciding whether a sentence is grammatical (although grammatical correction is a valid task), but rather in __parsing__, since parsing can discover structure in sentences which can be highly useful for a variety of tasks: semantic processing, IR, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZRRtsGz72dp1"
   },
   "source": [
    "Although there exist a plethora of different of syntactic theories, __constituency (aka phrase structure) grammars__ and __dependency grammars__ have been especially important for NLP."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hF8T8lG22dp1"
   },
   "source": [
    "## Constituency grammars\n",
    "\n",
    "(Not totally unexpectedly,) Constituency grammars are based on the concept of a __constituent__, i.e., a word or a group of words that form a \"natural unit\", \"belong together\". This vague notion can be operationalized using various test,  e.g., the phrase\n",
    "\n",
    "> a nice little city\n",
    "\n",
    "is a constituent, e.g., since it can be\n",
    "\n",
    "+ put into various sentence frames like \"I wanted to visit ....\", \"Frankfurt is ...\"\n",
    "+ coordinated: \"Frankfurt is a nice little city and a metropolis at the same time.\"\n",
    "+ substituted by pronouns: \"I have visited a nice little city.\" -> \"I have visited it.\"\n",
    "+ an answer to a question: \"What did you want to visit?\" -- \"A nice little city\"\n",
    "\n",
    "an so on, see [the \"Constituents\" entry of Wikipedia](https://en.wikipedia.org/wiki/Constituent_(linguistics)) for more tests.\n",
    "\n",
    "The theoretical significance of constituents is that smaller ones can be grouped together to build a larger one, for example our \"a nice little city\" can be grouped with \"visited\" to form\n",
    "\n",
    "> visited a nice little city\n",
    "\n",
    "which is a constituent again.\n",
    "\n",
    "Constituency grammars\n",
    "+ categorize constituents, and\n",
    "+ specify rules according to which constituents can be grouped together to build larger ones, eventually building up a whole sentence.\n",
    "\n",
    "### Context-free grammars (CFGs)\n",
    "\n",
    "Context-free grammars are basic, but still very useful constituency grammars, which, because of their simplicity and good computational properties have been frequently used in NLP applications. These grammars can be specified as finite set of __context free production rules__  of the form\n",
    "\n",
    "$\\alpha \\rightarrow \\beta_1 \\dots \\beta_n$\n",
    "\n",
    "where $\\alpha$ is a so called non-terminal symbol (constituent category), while $\\beta_1 \\dots \\beta_n$ are one or more non-terminal or terminal symbols (the latter are words in the language's lexicon). Among the non-terminals there is a distinguished $S$ start/sentence symbol. The rules are context-free, because the production rules for the categories are context independent (there can be only one symbol on the left).\n",
    "\n",
    "An example grammar for an (extremely small) fragment of English:\n",
    "\n",
    "<a href=\"https://www.researchgate.net/profile/Peter_Hellwig/publication/267632391/figure/fig9/AS:668635244789772@1536426473380/A-grammar-fragment-of-English_W640.jpg\"><img src=\"https://drive.google.com/uc?export=view&id=1wo__5Zb9BQc4-gljwVsqnUj7lxqzVjhC\"></a>\n",
    "\n",
    "(Example from [Hellwig (2006): Parsing with dependency grammars](https://www.researchgate.net/publication/267632391_Parsing_with_Dependency_Grammars))\n",
    "\n",
    "(The lexicon specifies so called insertion rules in a compressed form: if a $w$ word is in a category $c$ in the lexicon, then $c \\rightarrow w$ is a production rule of the grammar.)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TBYhzjUI2dp2"
   },
   "source": [
    "Parse trees provide a more perspicuous, essentially equivalent representation of the derivation:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dup-Pe_H2dp2"
   },
   "source": [
    "<a href=\"http://drive.google.com/uc?export=view&id=1blCWLNK4_mKoRiTuPGOkhLVa8pQY3omP\"><img src=\"https://drive.google.com/uc?export=view&id=1zLZy4wbAuRgvXP9l9XjbDEdjXg3yWWXk\" width=\"350\"></a>\n",
    "\n",
    "The edges of the tree indicate that the phrases are (direct) constituents of each other, that is, it shows the __constituency relation__ between constituents of the sentence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6R8xKawe2dp2"
   },
   "source": [
    "### Is the syntax of natural languages context-free?\n",
    "\n",
    "While context-free grammars can describe large fragments of natural languages, most linguists think that natural languages are actually not entirely context-free, since there are constructions that can be modeled only by context-sensitive rules. Since parsing context-sensitive languages (where the left side of rules can specify context requirements) is in general an NP-complete task, research has focused on so-called __mildly context sensitive languages__, that allow some context-sensitivity but still can be parsed in polynomial time. See the [Wikipedia entry on mildly context-sensitive languages](https://en.wikipedia.org/wiki/Mildly_context-sensitive_grammar_formalism) for some details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GYhhwJZS2dp3"
   },
   "source": [
    "## Dependency grammars\n",
    "\n",
    "### Headedness and dependency\n",
    "\n",
    "Although CFGs do not, many important constituency grammars (e.g., [Head-driven Phrase Structure Grammar](https://en.wikipedia.org/wiki/Head-driven_phrase_structure_grammar)) make heavy use of the assumption that every multi-word constituent contains a __head word__,  which determines the type of the constituent, and determines the syntactic organization and properties of the other parts. Continuing our example, the heads of the NPs \"the students\", \"their professor\" would be their nouns \"students\" and \"professors\", the VP \"love their professor\" would be headed by \"love\", which would be the head of the whole sentence as well:\n",
    "\n",
    "<a href=\"http://drive.google.com/uc?export=view&id=1msxgf6N62CAuffvbib2aVZEeGQeojTBo\"><img src=\"https://drive.google.com/uc?export=view&id=1oY_mWOMIpFph2FlwAVe2UyFueu6JgzCW\" width=\"350\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hHH6lAU52dp3"
   },
   "source": [
    "The notion of a constituent being \"headed\" by a word leads naturally to a notion of __dependency__ relationship between _words:_ if $c_2$ is a direct constituent of $c_1$ and their (different) heads are $h_2$ and $h_1$, then $h_2$ depends on $h_1$. Accordingly, the dependencies in the sentence would be\n",
    "\n",
    "<a href=\"http://drive.google.com/uc?export=view&id=1oTMteU6X05Yn7Nj01ILAqP1LKeqrH4mr\"><img src=\"https://drive.google.com/uc?export=view&id=1i3bR8gi-HRVMVWqIDd2qlW-_swjfogyL\" width=\"400\"></a>\n",
    "\n",
    "### Dependency without constituents\n",
    "\n",
    "Although as we have seen, the notion of dependency can be motivated from a constituency perspective, __dependency grammars__ make the dependency relationship between words the fundamental component of syntactic analysis. Similarly to the constituent-tests we have seen earlier, a number of tests/criterions have been suggested in the literature for dependency between words, e.g.\n",
    "\n",
    "$d$ depends on $h$ when\n",
    "\n",
    "+ $d$ modifies the meaning of $h$, makes it more specific, e.g. \"eats\" --> \"eats bread\", \"eats slowly\" etc.\n",
    "+ there is asymmetric relationship of omissibility between them: $d$ can be omitted from the sentence keeping $h$ but not vice versa\n",
    "\n",
    "Dependency grammars impose some important _global_ constraints on dependencies within a grammatical sentence:\n",
    "+ There is exactly one independent word (the root of the sentence).\n",
    "+ All other words depend directly on exactly one word.\n",
    "\n",
    "As a consequence, the the direct dependency graph of a sentence is a __tree__.\n",
    "\n",
    "In addition to this structure, typical dependency grammars also rely on a finite list of __dependency types__, which label the edges of the dependency trees. For instance, using the dependency types of the [Universal Dependencies treebank project](https://universaldependencies.org/), the spaCy dependency parser parses our example sentence as\n",
    "\n",
    "<a href=\"http://drive.google.com/uc?export=view&id=1XI-Usp7HVClkuoqm8-6XEfUV9Azr5gnD\"><img src=\"https://drive.google.com/uc?export=view&id=1F10wvEAxttZ_4gFVwjb9zF6obVk1i2P2\" width=\"500px\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3YbckMHf2dp4"
   },
   "source": [
    "Dependency grammars impose a number of constraints/rules on the permissible dependency relations between words of a sentence, and can therefore define a grammatical/well formed sentence as a sentence which has a permissible dependency tree analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7TTQ8O_G2dp4"
   },
   "source": [
    "## Constituency vs dependency grammars in NLP\n",
    "\n",
    "Historically, modern formal linguistics was dominated by constituency/phrase structure focused theories of syntax, and dependency grammar researchers were only a small minority group of dissenters. (Even though the notion of dependency arguably played central role in the ancient Indian and Greek grammars.) As a result, syntactic analysis in early NLP applications was based on constituency grammars (frequently on CFGs), but this gradually changed in the 2000s, when dependency grammars started to dominate the field. Some of the reasons for this change have been computational:\n",
    "\n",
    "+ dependency trees are in many respect simpler structures than phrase structure parse trees\n",
    "\n",
    "but the needs of semantic processing were also important:\n",
    "\n",
    "+ the predicate-argument analysis of sentences provided by dependency graphs is a very good starting point for event or frame-oriented semantic analysis.\n",
    "\n",
    "E.g.,  which representation seems more useful if your task is to extract events and participants from sentences?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0VD6PKql2dp4"
   },
   "source": [
    "<a href=\"http://drive.google.com/uc?export=view&id=1blCWLNK4_mKoRiTuPGOkhLVa8pQY3omP\"><img src=\"https://drive.google.com/uc?export=view&id=1zLZy4wbAuRgvXP9l9XjbDEdjXg3yWWXk\" width=\"350\"></a>\n",
    "<a href=\"http://drive.google.com/uc?export=view&id=1XI-Usp7HVClkuoqm8-6XEfUV9Azr5gnD\"><img src=\"https://drive.google.com/uc?export=view&id=1F10wvEAxttZ_4gFVwjb9zF6obVk1i2P2\" width=\"500px\"></a>\n",
    "\n",
    "(We will talk about these semantic tasks later.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cJ6-JjY62dp4"
   },
   "source": [
    "# Parsing\n",
    "\n",
    "Given a syntactic theory, the central syntactic task is to analyze the structure of putative sentences by constructing a representation of their structure which shows that they satisfy the conditions/constraints the theory specifies for grammatical sentences. For constituency grammars this means the identification of constituents and the construction of a constituency parse tree, while in the case of dependency grammars the identification of direct dependencies and the construction of a dependency tree.\n",
    "\n",
    "In modern NLP practice, the syntactic theories are typically specified, a least in part, implicitly, using so called __treebanks__, that is, a data set consisting of sentences annotated with their parse trees. This makes parsing a __structured supervised learning task__: given a training set of $\\langle \\mathrm{sentence}, \\mathrm{parse}~\\mathrm{tree} \\rangle$ pairs, learn to predict the parse tree of unseen sentences.\n",
    "\n",
    "## Performance metrics\n",
    "\n",
    "__Constituency grammar parsers__\n",
    "\n",
    "For constituency grammar parser, the standard evaluation is based on the number of correctly identified constituents relative to the ground truth (\"gold corpus\"). Recall and precision can be calculated in the usual way, and from those the F1 score, which is the most common metric:\n",
    "\n",
    "$$\\mathrm{Parser~~precision} = \\frac{\\#(\\mathrm{correct~~parser~~constituents)}}{\\#(\\mathrm{all~~parser~~constituents)}}$$\n",
    "\n",
    "$$\\mathrm{Parser~~recall}=\\frac{\\#(\\mathrm{correct~~parser~~constituents)}}{\\#(\\mathrm{all~~correct~~constituents)}}$$\n",
    "\n",
    "$$\\mathrm{F1~score}=\\frac{2pr}{p+r}$$\n",
    "\n",
    "__Dependency grammar parsers__\n",
    "\n",
    "Here the most common metrics are\n",
    "\n",
    "+ __UAS (Unlabeled Attachment Score)__: The percentage of words that are attached to the correct head.\n",
    "+ __UAS (Labeled Attachment Score)__: The percentage of words that are attached to the correct head with the correct dependency label.\n",
    "\n",
    "Dependency parsing is done through a state machine in combination with classification algorithms. You can find it in the extended version of this notebook"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "383.6px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
